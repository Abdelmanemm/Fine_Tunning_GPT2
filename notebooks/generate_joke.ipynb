{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Workspace/Prodigy_InfoTech_Internship/task1-Text_Genration_with_gpt2/src/task1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=r\".*clean_up_tokenization_spaces.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tokenizer and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer and specify padding token\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# load fine tunned model and specify padding token\n",
    "model = GPT2LMHeadModel.from_pretrained('/mnt/d/Workspace/Prodigy_InfoTech_Internship/task1-Text_Genration_with_gpt2/model/checkpoint-30000/')\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate joke Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a joke\n",
    "def generate_joke(prompt):\n",
    "    # Use torch.no_grad() to avoid unnecessary computation of gradients\n",
    "    with torch.no_grad():\n",
    "        # Tokenize input and get input ids and attention mask to use it in generatng output\n",
    "        inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs.get(\"attention_mask\", None)\n",
    "\n",
    "        # Generate joke\n",
    "        outputs = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            num_return_sequences=1,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            max_new_tokens =100,\n",
    "            do_sample=True,  \n",
    "            temperature=0.9,\n",
    "            top_k=50,\n",
    "            top_p=0.9\n",
    "        )\n",
    "\n",
    "        # Decode and clean up the generated joke\n",
    "        generated_joke = tokenizer.decode(outputs[0], skip_special_tokens=True).split('\\n')[0]\n",
    "\n",
    "    return generated_joke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't programmers trust elevators? They always go up and down stairs.  \n",
      "Why did the bicycle fall over? because it was stationary\n",
      "Why don't skeletons fight each other? Because they can't stand up for themselves. \n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    prompt = input(\"Please enter a title for the joke: \")\n",
    "    joke = generate_joke(prompt)\n",
    "    print(joke)\n",
    "    get_user_input = input(\"say another Joke ? yes or no \").lower()\n",
    "    if get_user_input in  ['no','n']:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "task1gpt2",
   "language": "python",
   "name": "task1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
